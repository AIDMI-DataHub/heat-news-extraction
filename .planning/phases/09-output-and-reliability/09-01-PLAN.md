---
phase: 09-output-and-reliability
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/output/_writers.py
  - src/output/_metadata.py
  - src/output/__init__.py
autonomous: true

must_haves:
  truths:
    - "Given a list of Article objects, JSON files are written organized by date/state_slug directories"
    - "Given a list of Article objects, CSV files are written organized by date/state_slug directories with identical content to JSON"
    - "Output directories are created on write, not pre-created"
    - "Collection metadata (timestamp, sources, query terms, article counts) is written as a separate JSON file"
    - "Indian language scripts (Devanagari, Tamil, etc.) are preserved correctly in JSON output (ensure_ascii=False)"
  artifacts:
    - path: "src/output/_writers.py"
      provides: "write_json, write_csv, write_collection_output async functions"
      min_lines: 60
    - path: "src/output/_metadata.py"
      provides: "CollectionMetadata frozen Pydantic model"
      min_lines: 20
    - path: "src/output/__init__.py"
      provides: "Re-exports write_json, write_csv, write_collection_output, CollectionMetadata"
  key_links:
    - from: "src/output/_writers.py"
      to: "src/models/article.py"
      via: "Article.model_dump(mode='json') for serialization"
      pattern: "model_dump.*mode.*json"
    - from: "src/output/_writers.py"
      to: "aiofiles"
      via: "async file I/O for non-blocking writes"
      pattern: "aiofiles\\.open"
    - from: "src/output/_writers.py"
      to: "src/output/_metadata.py"
      via: "CollectionMetadata import for metadata writing"
      pattern: "CollectionMetadata"
---

<objective>
Create JSON and CSV output writers with collection metadata for the heat news extraction pipeline.

Purpose: The pipeline must persist collected articles in organized, human-readable formats (JSON and CSV) grouped by date and state, with collection-level metadata for traceability (OUTP-01, OUTP-02, OUTP-03, OUTP-04).

Output: Three files in src/output/ -- _writers.py (async JSON/CSV writing functions), _metadata.py (CollectionMetadata Pydantic model), __init__.py (re-exports).
</objective>

<execution_context>
@/Users/akashyadav/.claude/get-shit-done/workflows/execute-plan.md
@/Users/akashyadav/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/models/article.py
@src/output/__init__.py
@requirements.txt
</context>

<tasks>

<task type="auto">
  <name>Task 1: CollectionMetadata model and output writers (JSON + CSV)</name>
  <files>src/output/_metadata.py, src/output/_writers.py, src/output/__init__.py</files>
  <action>
**_metadata.py:**

Create a frozen Pydantic model `CollectionMetadata` with these fields:
- `collection_timestamp: datetime` (IST-aware, when collection started)
- `sources_queried: list[str]` (e.g. ["google_news", "newsdata", "gnews"])
- `query_terms_used: list[str]` (unique heat terms used across all queries)
- `counts: dict` with keys: `articles_found: int`, `articles_extracted: int`, `articles_filtered: int`

Use `ConfigDict(frozen=True)` to match the project convention of frozen models.

**_writers.py:**

Create three async functions:

1. `async def write_json(articles: list[Article], output_dir: Path, state_slug: str) -> Path`:
   - Create directory `output_dir / state_slug` using `pathlib.Path.mkdir(parents=True, exist_ok=True)` (OUTP-03: dirs created on write)
   - Build dict: `{"state": articles[0].state if articles else state_slug, "date": output_dir.name, "article_count": len(articles), "articles": [a.model_dump(mode='json') for a in articles]}`
   - Use `json.dumps(data, indent=2, ensure_ascii=False)` for Indian scripts (Pitfall 4 from research)
   - Write via `aiofiles.open(path, 'w', encoding='utf-8')` (Pitfall 1: no blocking I/O)
   - Return the written file path

2. `async def write_csv(articles: list[Article], output_dir: Path, state_slug: str) -> Path`:
   - Create directory same as JSON writer
   - Use StringIO bridge pattern (from research Pattern 2): build CSV in `io.StringIO` buffer with `csv.DictWriter`, then write via `aiofiles`
   - Fieldnames derived from `articles[0].model_dump(mode='json').keys()`
   - Include `full_text` in CSV per OUTP-02 ("match JSON structure")
   - Handle empty articles list (write empty file)
   - Return the written file path

3. `async def write_collection_output(articles: list[Article], output_dir: Path, metadata: CollectionMetadata) -> dict[str, list[Path]]`:
   - Group articles by `article.state.lower().replace(" ", "-").replace("&", "and")` to derive state_slug (simple slug from state name)
   - For each state_slug group, call `write_json()` and `write_csv()` in parallel using `asyncio.gather`
   - Write metadata file at `output_dir / "_metadata.json"` via aiofiles with `metadata.model_dump(mode='json')`
   - Return dict: `{"json": [json_paths...], "csv": [csv_paths...], "metadata": [metadata_path]}`

Import and use: `from src.models.article import Article`, `from src.output._metadata import CollectionMetadata`.

**__init__.py:**

Update to re-export: `write_json`, `write_csv`, `write_collection_output`, `CollectionMetadata`.
Add `__all__` list with these four symbols.
  </action>
  <verify>
Run: `python -c "from src.output import write_json, write_csv, write_collection_output, CollectionMetadata; print('All output symbols importable')"` -- must succeed without errors.
  </verify>
  <done>
All four symbols (write_json, write_csv, write_collection_output, CollectionMetadata) are importable from src.output. The functions accept Article lists and Path objects, write JSON/CSV with async I/O, create directories on write, and include ensure_ascii=False for Indian scripts. CollectionMetadata model holds collection-level statistics.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from src.output import write_json, write_csv, write_collection_output, CollectionMetadata"` succeeds
2. `python -c "from src.output._metadata import CollectionMetadata; m = CollectionMetadata(collection_timestamp='2026-02-11T10:00:00+05:30', sources_queried=['google_news'], query_terms_used=['heatwave'], counts={'articles_found': 10, 'articles_extracted': 8, 'articles_filtered': 6}); print(m)"` succeeds
3. `grep -c 'ensure_ascii=False' src/output/_writers.py` returns at least 1
4. `grep -c 'aiofiles.open' src/output/_writers.py` returns at least 3
5. `grep -c 'mkdir.*parents=True' src/output/_writers.py` returns at least 1
</verification>

<success_criteria>
- CollectionMetadata is a frozen Pydantic model with collection_timestamp, sources_queried, query_terms_used, counts
- write_json writes per-state JSON with Article.model_dump(mode='json') and ensure_ascii=False
- write_csv writes per-state CSV via StringIO + DictWriter bridge with aiofiles
- write_collection_output groups articles by state slug, writes JSON+CSV+metadata
- All file I/O uses aiofiles (no blocking open())
- Directories created on write via mkdir(parents=True, exist_ok=True)
</success_criteria>

<output>
After completion, create `.planning/phases/09-output-and-reliability/09-01-SUMMARY.md`
</output>
