---
phase: 09-output-and-reliability
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/reliability/__init__.py
  - src/reliability/_circuit_breaker.py
  - src/reliability/_retry.py
  - src/reliability/_checkpoint.py
  - src/sources/google_news.py
  - src/sources/newsdata.py
  - src/sources/gnews.py
  - src/query/_scheduler.py
autonomous: true

must_haves:
  truths:
    - "Each news source has an independent circuit breaker that opens after consecutive failures and auto-recovers after a timeout"
    - "HTTP 429 rate limit errors trigger exponential backoff with jitter via tenacity, not immediate failure"
    - "Sources re-raise RateLimitError for HTTP 429 instead of silently returning empty lists, enabling tenacity retry"
    - "Circuit breaker returns success=True with error='circuit_breaker_open' (expected skip, same pattern as budget_exhausted)"
    - "Checkpoint store tracks completed query keys and persists to disk after each save"
    - "Checkpoint store can load from disk on restart and report which queries are already completed"
  artifacts:
    - path: "src/reliability/_circuit_breaker.py"
      provides: "CircuitBreaker class with closed/open/half_open state machine"
      min_lines: 40
    - path: "src/reliability/_retry.py"
      provides: "RateLimitError exception and with_rate_limit_retry tenacity decorator factory"
      min_lines: 25
    - path: "src/reliability/_checkpoint.py"
      provides: "CheckpointStore class with query_key, is_completed, mark_completed, save, load"
      min_lines: 40
    - path: "src/reliability/__init__.py"
      provides: "Re-exports CircuitBreaker, RateLimitError, with_rate_limit_retry, CheckpointStore"
    - path: "src/query/_scheduler.py"
      provides: "SourceScheduler.execute() with circuit breaker check before budget check and success/failure recording"
  key_links:
    - from: "src/reliability/_retry.py"
      to: "tenacity"
      via: "wait_exponential_jitter and retry_if_exception"
      pattern: "tenacity\\.retry|wait_exponential_jitter"
    - from: "src/query/_scheduler.py"
      to: "src/reliability/_circuit_breaker.py"
      via: "CircuitBreaker.is_open check before execution, record_success/record_failure after"
      pattern: "circuit_breaker|is_open|record_success|record_failure"
    - from: "src/sources/newsdata.py"
      to: "src/reliability/_retry.py"
      via: "Re-raise RateLimitError for HTTP 429 instead of returning []"
      pattern: "RateLimitError"
    - from: "src/reliability/_checkpoint.py"
      to: "aiofiles"
      via: "Async file I/O for checkpoint persistence"
      pattern: "aiofiles\\.open"
---

<objective>
Create reliability primitives (circuit breaker, tenacity retry, checkpoint store) and integrate circuit breaker + retry into the existing source/scheduler code.

Purpose: The pipeline needs per-source circuit breakers (RELI-03), exponential backoff with jitter for rate limits (RELI-04), and a checkpoint store for crash recovery (RELI-01, RELI-02). The circuit breaker and retry must be wired into the existing SourceScheduler and source adapters.

Output: New src/reliability/ package with three modules, plus modifications to the three source files and the scheduler.
</objective>

<execution_context>
@/Users/akashyadav/.claude/get-shit-done/workflows/execute-plan.md
@/Users/akashyadav/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/query/_scheduler.py
@src/query/_models.py
@src/sources/google_news.py
@src/sources/newsdata.py
@src/sources/gnews.py
@.planning/phases/09-output-and-reliability/09-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Reliability primitives -- CircuitBreaker, RateLimitError, retry decorator, CheckpointStore</name>
  <files>src/reliability/__init__.py, src/reliability/_circuit_breaker.py, src/reliability/_retry.py, src/reliability/_checkpoint.py</files>
  <action>
Create `src/reliability/` package directory.

**_circuit_breaker.py:**

Implement `CircuitBreaker` class exactly as specified in research Pattern 4:
- Constructor: `name: str`, `failure_threshold: int = 5`, `reset_timeout: float = 60.0`
- Internal state: `_failure_count: int`, `_last_failure_time: float`, `_state: str` (one of "closed", "open", "half_open")
- Property `is_open -> bool`: If state is "open", check if `time.monotonic() - _last_failure_time >= _reset_timeout`; if so, transition to "half_open" and return False; otherwise return True. If state is not "open", return False.
- `record_success()`: Reset `_failure_count = 0`, set `_state = "closed"`. If transitioning from half_open, log info.
- `record_failure()`: Increment `_failure_count`, set `_last_failure_time = time.monotonic()`. If `_failure_count >= _failure_threshold`, set `_state = "open"` and log warning.
- Property `state -> str`: Return current state (for logging/debugging).
- Use `time.monotonic()` for timing (per project decision from Phase 6).

**_retry.py:**

1. Define `RateLimitError(Exception)` with `status_code: int` and `source: str` attributes. Constructor takes `status_code`, `source`, optional `message`.

2. Define `is_rate_limit_error(exc: BaseException) -> bool` predicate: returns True if `isinstance(exc, RateLimitError)`.

3. Define `with_rate_limit_retry(max_attempts: int = 5)` factory that returns a `tenacity.retry` decorator:
   - `wait=tenacity.wait_exponential_jitter(initial=1, max=60, jitter=5)`
   - `stop=tenacity.stop_after_attempt(max_attempts)`
   - `retry=tenacity.retry_if_exception(is_rate_limit_error)`
   - `before_sleep=tenacity.before_sleep_log(logger, logging.WARNING)`
   - `reraise=True`

**_checkpoint.py:**

Implement `CheckpointStore` class exactly as specified in research Pattern 5:
- Constructor: `checkpoint_path: Path`
- Internal state: `_completed: set[str]`
- Static method `query_key(q: Query) -> str`: Compute `hashlib.sha256(f'{q.source_hint}|{q.state_slug}|{q.language}|{q.level}|{q.query_string}'.encode()).hexdigest()[:16]`
- `is_completed(q: Query) -> bool`: Check if query_key is in `_completed`
- `async def mark_completed(q: Query) -> None`: Add query_key to `_completed`
- `async def save() -> None`: Create parent directory with `mkdir(parents=True, exist_ok=True)`, write JSON `{"completed_queries": sorted(self._completed)}` via `aiofiles.open`
- `async def load() -> None`: If path exists, read and parse JSON via `aiofiles.open`, populate `_completed` set
- Property `completed_count -> int`: Return `len(self._completed)`

Import Query type with `TYPE_CHECKING` guard to avoid circular imports (same pattern as _scheduler.py).

**__init__.py:**

Re-export: `CircuitBreaker`, `RateLimitError`, `with_rate_limit_retry`, `CheckpointStore`.
Add `__all__` list.
  </action>
  <verify>
Run: `python -c "from src.reliability import CircuitBreaker, RateLimitError, with_rate_limit_retry, CheckpointStore; print('All reliability symbols importable')"` -- must succeed.
  </verify>
  <done>
All four symbols are importable from src.reliability. CircuitBreaker has closed/open/half_open states with configurable threshold and timeout. RateLimitError is a dedicated exception for HTTP 429. with_rate_limit_retry returns a tenacity decorator with exponential backoff + jitter. CheckpointStore tracks query completion via SHA-256 keys and persists to JSON via aiofiles.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire circuit breaker into SourceScheduler and RateLimitError into sources</name>
  <files>src/sources/google_news.py, src/sources/newsdata.py, src/sources/gnews.py, src/query/_scheduler.py</files>
  <action>
**Source modifications (google_news.py, newsdata.py, gnews.py):**

In each source's `search()` method, modify the `httpx.HTTPStatusError` handler to re-raise HTTP 429 as `RateLimitError` instead of returning `[]`:

For `google_news.py`: In the `except httpx.HTTPStatusError as exc:` block, add a check BEFORE the existing handler:
```python
if exc.response.status_code == 429:
    from src.reliability._retry import RateLimitError
    raise RateLimitError(status_code=429, source="google_news") from exc
```
Keep all other status code handling unchanged. The import is inside the except block to avoid circular imports and because it only fires on the rare 429 path.

For `newsdata.py`: In the `except httpx.HTTPStatusError as exc:` block, modify the `elif status == 429:` branch to raise instead of returning:
```python
elif status == 429:
    from src.reliability._retry import RateLimitError
    raise RateLimitError(status_code=429, source="newsdata") from exc
```
Remove the logger.warning for 429 from this branch (the tenacity before_sleep_log will handle logging).

For `gnews.py`: In the `except httpx.HTTPStatusError as exc:` block, modify the `elif status == 429:` branch to raise instead of returning:
```python
elif status == 429:
    from src.reliability._retry import RateLimitError
    raise RateLimitError(status_code=429, source="gnews") from exc
```
Remove the logger.warning for 429 from this branch.

This preserves the "never raises" contract for all errors EXCEPT HTTP 429, which is now explicitly propagated for tenacity to catch (per research Pitfall 7 solution).

**SourceScheduler modifications (_scheduler.py):**

1. Add `circuit_breaker: CircuitBreaker | None = None` parameter to `__init__`. Store as `self._circuit_breaker`. Use `TYPE_CHECKING` import for `CircuitBreaker` if needed; at runtime import inline in the body.

2. In `execute()` method, add circuit breaker check as the FIRST check (before budget check, per research: "Circuit breaker check should happen before rate limiter acquire -- fail fast, don't wait"):
```python
# 0. Circuit breaker check (before budget, before rate limiter)
if self._circuit_breaker is not None and self._circuit_breaker.is_open:
    logger.debug("%s: circuit breaker open, skipping query", self._name)
    return QueryResult(
        query=query,
        source_name=self._name,
        articles=[],
        success=True,
        error="circuit_breaker_open",
    )
```

3. Wrap the source call with the tenacity retry decorator. Import `with_rate_limit_retry` from `src.reliability._retry`. Apply it to the HTTP call section. The cleanest approach: define a local async function `_call_source()` inside `execute()` that calls `self._source.search(...)`, decorate it with `@with_rate_limit_retry()`, and call it. This way tenacity retries the source call when RateLimitError propagates from the source.

4. After successful execution (articles returned), call `self._circuit_breaker.record_success()` if circuit breaker is set.

5. In the except block (when the source call fails with a non-retriable error or tenacity gives up), call `self._circuit_breaker.record_failure()` if circuit breaker is set.

6. Update the three factory functions to accept an optional `circuit_breaker` parameter and pass it through:
```python
def create_google_scheduler(source: NewsSource, circuit_breaker: CircuitBreaker | None = None) -> SourceScheduler:
```
  </action>
  <verify>
Run: `python -c "from src.query._scheduler import SourceScheduler, create_google_scheduler; print('Scheduler imports OK')"` -- must succeed.
Run: `python -c "from src.sources.google_news import GoogleNewsSource; from src.sources.newsdata import NewsDataSource; from src.sources.gnews import GNewsSource; print('All sources importable')"` -- must succeed.
Run: `grep -c 'RateLimitError' src/sources/google_news.py src/sources/newsdata.py src/sources/gnews.py` -- each file should have at least 1 occurrence.
Run: `grep -c 'circuit_breaker' src/query/_scheduler.py` -- should have multiple occurrences.
  </verify>
  <done>
All three sources re-raise RateLimitError for HTTP 429 instead of silently returning []. SourceScheduler.execute() checks circuit breaker state before budget/rate limiting, wraps source calls with tenacity retry (exponential backoff + jitter for RateLimitError), and records success/failure on the circuit breaker. Factory functions accept optional circuit_breaker parameter.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from src.reliability import CircuitBreaker, RateLimitError, with_rate_limit_retry, CheckpointStore"` succeeds
2. `python -c "from src.query._scheduler import SourceScheduler; print('OK')"` succeeds
3. `python -c "from src.sources.google_news import GoogleNewsSource; from src.sources.newsdata import NewsDataSource; from src.sources.gnews import GNewsSource; print('OK')"` succeeds
4. `grep 'RateLimitError' src/sources/google_news.py src/sources/newsdata.py src/sources/gnews.py` shows matches in all three
5. `grep 'circuit_breaker' src/query/_scheduler.py` shows multiple matches
6. `grep 'record_success\|record_failure' src/query/_scheduler.py` shows both
7. `grep 'with_rate_limit_retry\|tenacity' src/query/_scheduler.py` shows retry integration
</verification>

<success_criteria>
- CircuitBreaker with closed/open/half_open states, configurable threshold and timeout, time.monotonic() timing
- RateLimitError exception raised by sources ONLY for HTTP 429
- Tenacity retry decorator with wait_exponential_jitter(initial=1, max=60, jitter=5), stop_after_attempt(5)
- CheckpointStore with SHA-256 query keys, aiofiles persistence, load/save/is_completed API
- SourceScheduler checks circuit breaker first (fail fast), records success/failure, retries RateLimitError via tenacity
- Source "never raises" contract preserved for all errors except HTTP 429 (which is retried by tenacity at the scheduler level)
- Factory functions accept optional circuit_breaker parameter
</success_criteria>

<output>
After completion, create `.planning/phases/09-output-and-reliability/09-02-SUMMARY.md`
</output>
