---
phase: 01-project-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - requirements.txt
  - main.py
  - src/__init__.py
  - src/sources/__init__.py
  - src/models/__init__.py
  - src/extraction/__init__.py
  - src/output/__init__.py
autonomous: true

must_haves:
  truths:
    - "Running `python main.py` executes without import errors and exits cleanly with exit code 0"
    - "All six core dependencies (httpx, feedparser, trafilatura, pydantic, tenacity, aiofiles) are installed and importable"
    - "No browser dependencies (selenium, playwright, puppeteer) exist in requirements.txt or in the installed dependency tree"
    - "Project has src/ directory with four sub-modules: sources, models, extraction, output -- each with __init__.py"
  artifacts:
    - path: "requirements.txt"
      provides: "Pinned dependency versions for reproducible installs"
      contains: "httpx"
    - path: "main.py"
      provides: "Single entry point for the pipeline"
      min_lines: 10
    - path: "src/__init__.py"
      provides: "Root package marker"
    - path: "src/sources/__init__.py"
      provides: "Sources sub-package marker"
    - path: "src/models/__init__.py"
      provides: "Models sub-package marker"
    - path: "src/extraction/__init__.py"
      provides: "Extraction sub-package marker"
    - path: "src/output/__init__.py"
      provides: "Output sub-package marker"
  key_links:
    - from: "main.py"
      to: "src.sources"
      via: "import statement"
      pattern: "from src\\.sources|import src\\.sources"
    - from: "main.py"
      to: "src.models"
      via: "import statement"
      pattern: "from src\\.models|import src\\.models"
    - from: "main.py"
      to: "src.extraction"
      via: "import statement"
      pattern: "from src\\.extraction|import src\\.extraction"
    - from: "main.py"
      to: "src.output"
      via: "import statement"
      pattern: "from src\\.output|import src\\.output"
---

<objective>
Create the complete project scaffolding for the heat news extraction pipeline: directory structure, pinned dependencies, and a working entry point.

Purpose: Establish the foundation that all subsequent phases build upon -- a clean, importable Python package structure with all core libraries available.
Output: A runnable project skeleton where `python main.py` succeeds with zero errors.
</objective>

<execution_context>
@/Users/akashyadav/.claude/get-shit-done/workflows/execute-plan.md
@/Users/akashyadav/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create project directory structure and pinned requirements.txt</name>
  <files>
    requirements.txt
    src/__init__.py
    src/sources/__init__.py
    src/models/__init__.py
    src/extraction/__init__.py
    src/output/__init__.py
    .gitignore
  </files>
  <action>
    1. Create the `src/` package directory with four sub-packages:
       - `src/sources/` -- will hold news source adapters (Google News RSS, NewsData.io, GNews)
       - `src/models/` -- will hold Pydantic data models (Article, SearchResult, etc.)
       - `src/extraction/` -- will hold article text extraction logic (trafilatura wrapper)
       - `src/output/` -- will hold JSON/CSV output writers

    2. Create `__init__.py` in each directory. Each `__init__.py` should contain:
       - A module-level docstring describing the sub-package's purpose
       - Nothing else (no imports yet -- those come in later phases)

    3. Create `requirements.txt` with these exact pinned dependencies:
       ```
       httpx==0.28.1
       feedparser==6.0.11
       trafilatura==2.0.0
       pydantic==2.10.6
       tenacity==9.0.0
       aiofiles==24.1.0
       ```
       Use the latest stable versions available as of early 2025. Pin to exact versions (==), not ranges.
       CRITICAL: Do NOT include selenium, playwright, pyppeteer, or any browser automation library.

    4. Create `.gitignore` with standard Python entries:
       ```
       __pycache__/
       *.py[cod]
       *$py.class
       .env
       venv/
       .venv/
       *.egg-info/
       dist/
       build/
       .pytest_cache/
       data/
       output/
       ```

    5. Install the dependencies:
       ```bash
       pip install -r requirements.txt
       ```

    6. Verify no browser deps crept in:
       ```bash
       pip list | grep -iE "selenium|playwright|pyppeteer|puppeteer"
       ```
       This MUST return empty (no matches).
  </action>
  <verify>
    Run:
    - `python -c "import httpx, feedparser, trafilatura, pydantic, tenacity, aiofiles; print('All imports OK')"` -- must print "All imports OK"
    - `pip list | grep -iE "selenium|playwright|pyppeteer"` -- must return empty
    - `python -c "import src; import src.sources; import src.models; import src.extraction; import src.output; print('Package structure OK')"` -- must print "Package structure OK"
  </verify>
  <done>
    requirements.txt exists with 6 pinned dependencies; all install successfully; no browser deps in tree; src/ package with 4 sub-packages all importable.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create main.py entry point with module imports and clean execution</name>
  <files>
    main.py
  </files>
  <action>
    Create `main.py` at the project root as the single entry point for the pipeline. It should:

    1. Import all four sub-packages to verify the package structure works:
       ```python
       from src import sources, models, extraction, output
       ```

    2. Import the core third-party libraries to verify dependencies are available:
       ```python
       import httpx
       import feedparser
       import trafilatura
       import pydantic
       import tenacity
       import aiofiles
       ```

    3. Define an `async def main()` function that:
       - Prints a startup banner: "Heat News Extraction Pipeline"
       - Prints the versions of key libraries (httpx, pydantic, trafilatura) for diagnostics
       - Prints "Pipeline modules loaded: sources, models, extraction, output"
       - Prints "Ready. (No tasks configured yet -- pipeline stages will be added in subsequent phases.)"
       - Returns cleanly (exit code 0)

    4. Use `asyncio.run(main())` at the bottom (the pipeline will be async in later phases, so start with async entry point now).

    5. Include a module-level docstring explaining this is the single entry point for the heat news extraction pipeline.

    Do NOT add argument parsing, configuration loading, or any actual pipeline logic -- that comes in later phases. This is purely a "hello world" that proves the skeleton works.
  </action>
  <verify>
    Run:
    - `python main.py` -- must execute without errors, print the startup banner and module-loaded message, and exit with code 0
    - `python -c "import sys; sys.exit(0 if __import__('subprocess').run(['python', 'main.py']).returncode == 0 else 1)"` -- confirms exit code 0
  </verify>
  <done>
    `python main.py` runs successfully, imports all 4 sub-packages and all 6 core dependencies, prints diagnostic output, and exits with code 0. No import errors, no warnings.
  </done>
</task>

</tasks>

<verification>
Run all checks in sequence:

1. **Dependencies installed:**
   ```bash
   python -c "import httpx, feedparser, trafilatura, pydantic, tenacity, aiofiles; print('OK')"
   ```

2. **No browser deps:**
   ```bash
   pip list | grep -iE "selenium|playwright|pyppeteer|puppeteer"
   ```
   Must return empty.

3. **Package structure:**
   ```bash
   python -c "from src import sources, models, extraction, output; print('OK')"
   ```

4. **Entry point runs:**
   ```bash
   python main.py
   ```
   Must exit 0 with no errors.

5. **Directory structure exists:**
   ```bash
   ls src/__init__.py src/sources/__init__.py src/models/__init__.py src/extraction/__init__.py src/output/__init__.py
   ```
   All files must exist.
</verification>

<success_criteria>
- `python main.py` executes cleanly with exit code 0
- All 6 core dependencies importable
- Zero browser dependencies in pip list
- 4 sub-packages under src/ all importable
- requirements.txt contains exactly 6 pinned dependencies
</success_criteria>

<output>
After completion, create `.planning/phases/01-project-foundation/01-01-SUMMARY.md`
</output>
