---
phase: 06-query-engine-and-scheduling
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/query/__init__.py
  - src/query/_models.py
  - src/query/_generator.py
autonomous: true

must_haves:
  truths:
    - "QueryGenerator produces state-level queries for all 36 states/UTs across all relevant languages"
    - "Each state-language pair generates category-based OR-combined queries for Google News (8 per pair)"
    - "Each state-language pair generates a single broad query for NewsData.io (512 char limit) and GNews (200 char limit)"
    - "District-level queries batch multiple district names per query to stay within character limits"
    - "Multi-word terms and district names are quoted to prevent OR-splitting"
  artifacts:
    - path: "src/query/_models.py"
      provides: "Query and QueryResult frozen dataclasses"
      contains: "class Query"
    - path: "src/query/_generator.py"
      provides: "QueryGenerator with state-level and district-level query generation"
      contains: "class QueryGenerator"
    - path: "src/query/__init__.py"
      provides: "Package re-exports for query module"
      contains: "QueryGenerator"
  key_links:
    - from: "src/query/_generator.py"
      to: "src/data/geo_loader.py"
      via: "imports StateUT, District"
      pattern: "from src\\.data"
    - from: "src/query/_generator.py"
      to: "src/data/heat_terms_loader.py"
      via: "imports get_terms_by_category, TERM_CATEGORIES"
      pattern: "get_terms_by_category"
    - from: "src/query/_models.py"
      to: "src/models/article.py"
      via: "imports ArticleRef for QueryResult"
      pattern: "from src\\.models"
---

<objective>
Create the query data models (Query, QueryResult dataclasses) and the QueryGenerator that combines heat terms with geographic locations to produce API-ready query strings for all three sources.

Purpose: This is the foundation of Phase 6 -- without query generation, the scheduler and executor have nothing to work with. The generator must produce different query strategies per source (category-based OR-combining for Google News, broad queries for NewsData.io/GNews) and handle district batching within character limits.

Output: `src/query/_models.py` (Query/QueryResult), `src/query/_generator.py` (QueryGenerator), `src/query/__init__.py` (re-exports)
</objective>

<execution_context>
@/Users/akashyadav/.claude/get-shit-done/workflows/execute-plan.md
@/Users/akashyadav/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-query-engine-and-scheduling/06-RESEARCH.md

@src/data/geo_loader.py
@src/data/heat_terms_loader.py
@src/models/article.py
@src/sources/_protocol.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create query data models and query string builders</name>
  <files>src/query/__init__.py, src/query/_models.py</files>
  <action>
Create `src/query/` package with two files.

**src/query/_models.py:**
Create frozen dataclasses (not Pydantic -- internal objects, no I/O boundary validation needed):

1. `Query` (frozen dataclass):
   - `query_string: str` -- the actual search text ready for API
   - `language: str` -- ISO 639-1 code
   - `state: str` -- state/UT name (human-readable)
   - `state_slug: str` -- kebab-case for result tracking
   - `level: Literal["state", "district"]`
   - `category: str | None` -- heat term category (for Google News category queries, None for broad queries)
   - `source_hint: Literal["google", "newsdata", "gnews"]` -- which source this query is designed for
   - `districts: tuple[str, ...] = ()` -- district names if level == "district"

2. `QueryResult` (frozen dataclass):
   - `query: Query`
   - `source_name: str`
   - `articles: list[ArticleRef]`
   - `success: bool`
   - `error: str | None = None`

Import ArticleRef from `src.models.article`.

Also create two standalone helper functions in _models.py for query string construction:

3. `build_category_query(terms: list[str], location: str) -> str`:
   - Combines terms with OR, wraps in parens, appends location name.
   - Multi-word terms get double-quoted: `"heat wave"` not `heat wave`.
   - Result: `(term1 OR "heat wave" OR term3) Rajasthan`

4. `build_broad_query(terms: list[str], location: str, max_chars: int) -> str`:
   - Same as category query but picks highest-priority terms that fit within `max_chars`.
   - Terms are assumed priority-ordered (most important first).
   - Overhead: space + parens + location name.
   - Iterates terms, adding each until budget exhausted.
   - If no term fits, truncate first term as last resort.
   - Result: `(heatwave OR "heat stroke") Rajasthan`

5. `batch_districts(districts: list[str], heat_term: str, max_chars: int) -> list[str]`:
   - Batches district names into query strings within max_chars limit.
   - Each batch: `heat_term ("District1" OR "District2" OR District3)`
   - Multi-word district names get double-quoted.
   - Returns list of query strings.

**src/query/__init__.py:**
Re-export Query, QueryResult, build_category_query, build_broad_query, batch_districts.
Add QueryGenerator to __all__ (will be implemented in Task 2).
  </action>
  <verify>
Run: `python -c "from src.query import Query, QueryResult, build_category_query, build_broad_query, batch_districts; q = Query(query_string='test', language='en', state='Rajasthan', state_slug='rajasthan', level='state', category='heatwave', source_hint='google'); print(q); print(build_category_query(['heatwave', 'heat stroke', 'loo'], 'Rajasthan')); print(build_broad_query(['heatwave', 'heat stroke', 'sunburn'], 'Rajasthan', 200)); print(batch_districts(['Jaipur', 'Ambedkar Nagar', 'Lucknow'], 'heatwave', 200))"`
  </verify>
  <done>
Query and QueryResult dataclasses instantiate correctly. build_category_query produces `(heatwave OR "heat stroke" OR loo) Rajasthan`. build_broad_query respects character limit. batch_districts produces list of batched query strings with quoted multi-word names.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create QueryGenerator class for state-level and district-level query generation</name>
  <files>src/query/_generator.py, src/query/__init__.py</files>
  <action>
Create `src/query/_generator.py` with:

**class QueryGenerator:**

Constructor takes no arguments -- loads data from geo_loader and heat_terms_loader internally.

Methods:

1. `generate_state_queries(regions: list[StateUT]) -> dict[str, list[Query]]`:
   Returns dict keyed by source_hint ("google", "newsdata", "gnews").

   For each region and each language in region.languages:
   - **Google News queries** (source_hint="google"): Generate one Query per category (8 categories from TERM_CATEGORIES). Use `build_category_query(get_terms_by_category(lang, cat), region.name)`. Set `category=cat`. This produces ~800 queries (100 state-lang pairs x 8 categories).
   - **NewsData.io queries** (source_hint="newsdata"): Generate one broad Query per state-lang pair. Use `build_broad_query(get_terms_for_language(lang), region.name, 512)`. Set `category=None`. This produces ~100 queries.
   - **GNews queries** (source_hint="gnews"): Generate one broad Query per state-lang pair, BUT only for languages in `{"en", "hi", "bn", "ta", "te", "mr", "ml", "pa"}` (GNews supported set). Use `build_broad_query(get_terms_for_language(lang), region.name, 200)`. Set `category=None`. This produces ~87 queries.

2. `generate_district_queries(regions: list[StateUT], source_hint: Literal["google", "newsdata", "gnews"] = "google") -> list[Query]`:
   For each region, for each language:
   - Get top heat terms for this language (pick "heatwave" category terms as most productive).
   - Get district names from `region.districts`.
   - Use `batch_districts([d.name for d in region.districts], top_term, max_chars)` where max_chars depends on source_hint: google=2000, newsdata=512, gnews=200.
   - For each batched query string, create a Query with level="district", districts=(batch district names).
   - Use the first (highest priority) heatwave term for the heat_term in batch_districts. If no heatwave terms, fall back to first term from get_terms_for_language.

**GNEWS_SUPPORTED_LANGUAGES** constant at module level: `frozenset({"en", "hi", "bn", "ta", "te", "mr", "ml", "pa"})` -- mirrors GNewsSource._SUPPORTED_LANGUAGES but avoids importing from sources to prevent circular deps.

Update `src/query/__init__.py` to import and re-export QueryGenerator.
  </action>
  <verify>
Run: `python -c "
from src.data import get_all_regions
from src.query import QueryGenerator
gen = QueryGenerator()
regions = get_all_regions()
queries = gen.generate_state_queries(regions)
print('Google queries:', len(queries['google']))
print('NewsData queries:', len(queries['newsdata']))
print('GNews queries:', len(queries['gnews']))
# Verify district batching
from src.data import get_region_by_slug
up = get_region_by_slug('uttar-pradesh')
dq = gen.generate_district_queries([up])
print('UP district queries:', len(dq))
print('Sample query:', dq[0].query_string[:100] if dq else 'none')
"`
  </verify>
  <done>
Google queries count is ~800 (100 state-lang pairs x 8 categories). NewsData queries count is ~100. GNews queries count is ~87 (only 8-language pairs). District queries for Uttar Pradesh (75 districts) produce multiple batched queries. All Query objects have correct level, state_slug, language, category, and source_hint fields.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from src.query import Query, QueryResult, QueryGenerator, build_category_query, build_broad_query, batch_districts"` -- all imports succeed
2. Google News state queries total ~800 (8 categories x ~100 state-lang pairs)
3. NewsData.io state queries total ~100 (1 per state-lang pair)
4. GNews state queries total ~87 (1 per state-lang pair, only 8 supported languages)
5. All generated query strings have parenthesized OR groups followed by location name
6. No query string exceeds its source's character limit (2000 for Google, 512 for NewsData, 200 for GNews)
7. Multi-word terms and district names are double-quoted
8. District batching produces multiple queries when districts exceed character limit
</verification>

<success_criteria>
- Query/QueryResult dataclasses exist and are frozen
- QueryGenerator.generate_state_queries produces correctly-structured queries for all 3 sources
- QueryGenerator.generate_district_queries batches districts within character limits
- build_category_query and build_broad_query correctly handle OR-combining and quoting
- batch_districts correctly splits large district lists across multiple queries
- src/query package exports all public symbols
</success_criteria>

<output>
After completion, create `.planning/phases/06-query-engine-and-scheduling/06-01-SUMMARY.md`
</output>
