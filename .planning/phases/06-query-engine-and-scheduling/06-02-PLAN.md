---
phase: 06-query-engine-and-scheduling
plan: 02
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - src/query/_scheduler.py
  - src/query/__init__.py
autonomous: true

must_haves:
  truths:
    - "Each source has independent rate limiting that respects its specific constraints"
    - "Google News gets Semaphore(5) concurrency with 0.7s per-request delay and jitter"
    - "NewsData.io enforces 30-request rolling window per 15 minutes plus 200/day limit"
    - "GNews enforces 1 request per second plus 100/day limit"
    - "Budget-exhausted sources return empty results without making HTTP requests"
    - "SourceScheduler wraps any NewsSource and never raises exceptions"
  artifacts:
    - path: "src/query/_scheduler.py"
      provides: "SourceScheduler class with PerSecondLimiter and WindowLimiter"
      contains: "class SourceScheduler"
    - path: "src/query/__init__.py"
      provides: "Updated re-exports including SourceScheduler"
      contains: "SourceScheduler"
  key_links:
    - from: "src/query/_scheduler.py"
      to: "src/sources/_protocol.py"
      via: "imports NewsSource Protocol type for type hint"
      pattern: "from src\\.sources"
    - from: "src/query/_scheduler.py"
      to: "src/query/_models.py"
      via: "imports Query, QueryResult"
      pattern: "from src\\.query\\._models|from \\._models"
---

<objective>
Create the rate-limit-aware SourceScheduler that wraps each NewsSource with per-source rate limiting, daily budget tracking, and rolling window enforcement.

Purpose: The three news sources have wildly different rate limits (Google: ~100/hr soft limit, NewsData: 200/day with 30/15min window, GNews: 100/day at 1/sec). Without per-source scheduling, the pipeline would either exhaust API quotas instantly or fail with rate-limit errors. The scheduler makes each source self-regulating.

Output: `src/query/_scheduler.py` (SourceScheduler, PerSecondLimiter, WindowLimiter)
</objective>

<execution_context>
@/Users/akashyadav/.claude/get-shit-done/workflows/execute-plan.md
@/Users/akashyadav/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-query-engine-and-scheduling/06-RESEARCH.md
@.planning/phases/06-query-engine-and-scheduling/06-01-SUMMARY.md

@src/sources/_protocol.py
@src/query/_models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create rate limiters and SourceScheduler</name>
  <files>src/query/_scheduler.py</files>
  <action>
Create `src/query/_scheduler.py` with three classes:

**1. PerSecondLimiter:**
Simple per-second rate limiter using asyncio.

```
class PerSecondLimiter:
    def __init__(self, max_per_second: float, jitter: float = 0.0)
```

- `_interval = 1.0 / max_per_second`
- `_jitter` -- random additional delay (0 to jitter seconds) to avoid thundering herd
- `_lock = asyncio.Lock()` -- serialize access
- `_last = 0.0` -- last request time via time.monotonic()
- `async def acquire()`: Under lock, compute wait = `_last + _interval - now`. If wait > 0, `asyncio.sleep(wait + random.uniform(0, self._jitter))`. Update `_last = time.monotonic()`.

**2. WindowLimiter:**
Rolling window rate limiter (e.g., 30 requests per 15 minutes).

```
class WindowLimiter:
    def __init__(self, max_requests: int, window_seconds: int)
```

- `_max` -- max requests per window
- `_window` -- window duration in seconds
- `_timestamps: list[float]` -- request timestamps (monotonic)
- `async def acquire()`: Prune timestamps outside window. If `len >= _max`, compute wait = `oldest + window - now + 0.1`, then `asyncio.sleep(wait)`, then prune again. Append `time.monotonic()`.
- `@property exhausted_in_window -> bool`: Return True if window is full (for logging).

**3. SourceScheduler:**
Rate-limit-aware wrapper around a NewsSource.

```
class SourceScheduler:
    def __init__(
        self,
        source: NewsSource,
        name: str,
        daily_limit: int | None,       # None = unlimited (Google News)
        per_second_limiter: PerSecondLimiter | None = None,
        window_limiter: WindowLimiter | None = None,
        supported_languages: frozenset[str] | None = None,  # None = all
    )
```

State tracking:
- `_daily_count: int = 0`
- `_semaphore = asyncio.Semaphore(1)` -- default serialized, caller can override via concurrency param

Constructor also accepts `concurrency: int = 1` to set semaphore size (Google News uses 5).

Methods:

- `async def execute(self, query: Query) -> QueryResult`:
  1. Check `_is_budget_exhausted()` -- if daily_limit reached, return QueryResult with error="budget_exhausted", success=True.
  2. Check `supports_language(query.language)` -- if not supported, return QueryResult with error="unsupported_language", success=True.
  3. `async with self._semaphore:` (limits concurrency)
  4. If per_second_limiter: `await self._per_second_limiter.acquire()`
  5. If window_limiter: `await self._window_limiter.acquire()`
  6. Call `self._source.search(query.query_string, query.language, state=query.state, search_term=query.query_string)` inside try/except.
  7. Increment `_daily_count` (after request, before result processing).
  8. Return `QueryResult(query=query, source_name=self._name, articles=articles, success=True)`.
  9. On any exception: log warning, return `QueryResult(query=query, source_name=self._name, articles=[], success=False, error=str(exc))`. NEVER raise -- the executor depends on this.

- `def _is_budget_exhausted(self) -> bool`: Return `self._daily_limit is not None and self._daily_count >= self._daily_limit`.

- `def supports_language(self, lang: str) -> bool`: Return True if `_supported_languages is None` or `lang in _supported_languages`.

- `@property remaining_budget(self) -> int | None`: Return remaining daily budget or None if unlimited.

- `@property name(self) -> str`: Return `self._name`.

Import logging, asyncio, time, random at module top. Import Query, QueryResult from `._models`. Import NewsSource from `src.sources._protocol` for type hint only (or use string annotation).

Add module-level factory function for convenience:

```python
def create_google_scheduler(source: NewsSource) -> SourceScheduler:
    """Pre-configured scheduler for Google News RSS (unlimited, 5 concurrent, ~1.5/s with jitter)."""
    return SourceScheduler(
        source=source, name="google_news",
        daily_limit=None,
        per_second_limiter=PerSecondLimiter(max_per_second=1.5, jitter=0.3),
        concurrency=5,
    )

def create_newsdata_scheduler(source: NewsSource) -> SourceScheduler:
    """Pre-configured scheduler for NewsData.io (200/day, 30/15min window, 10/s)."""
    return SourceScheduler(
        source=source, name="newsdata",
        daily_limit=200,
        per_second_limiter=PerSecondLimiter(max_per_second=10.0),
        window_limiter=WindowLimiter(max_requests=30, window_seconds=900),
        supported_languages=frozenset({"en","hi","ta","te","bn","mr","gu","kn","ml","or","pa","as","ur","ne"}),
    )

def create_gnews_scheduler(source: NewsSource) -> SourceScheduler:
    """Pre-configured scheduler for GNews (100/day, 1/s)."""
    return SourceScheduler(
        source=source, name="gnews",
        daily_limit=100,
        per_second_limiter=PerSecondLimiter(max_per_second=1.0),
        supported_languages=frozenset({"en","hi","bn","ta","te","mr","ml","pa"}),
    )
```
  </action>
  <verify>
Run: `python -c "
import asyncio
from src.query._scheduler import PerSecondLimiter, WindowLimiter, SourceScheduler, create_google_scheduler, create_newsdata_scheduler, create_gnews_scheduler

# Test PerSecondLimiter instantiation
psl = PerSecondLimiter(max_per_second=1.5, jitter=0.3)
print('PerSecondLimiter created:', psl)

# Test WindowLimiter instantiation
wl = WindowLimiter(max_requests=30, window_seconds=900)
print('WindowLimiter created:', wl)

# Test SourceScheduler with mock
class MockSource:
    async def search(self, query, language, country='IN', *, state='', search_term=''):
        return []

mock = MockSource()
gs = create_google_scheduler(mock)
print('Google scheduler:', gs.name, 'budget:', gs.remaining_budget)
ns = create_newsdata_scheduler(mock)
print('NewsData scheduler:', ns.name, 'budget:', ns.remaining_budget)
gn = create_gnews_scheduler(mock)
print('GNews scheduler:', gn.name, 'budget:', gn.remaining_budget)

# Test execute
from src.query._models import Query
q = Query(query_string='test', language='en', state='Test', state_slug='test', level='state', category=None, source_hint='google')
result = asyncio.run(gs.execute(q))
print('Result success:', result.success, 'articles:', len(result.articles))
"`
  </verify>
  <done>
PerSecondLimiter, WindowLimiter, and SourceScheduler instantiate correctly. Factory functions create pre-configured schedulers with correct daily limits (None/200/100), language support, and concurrency settings. execute() returns QueryResult without raising. Budget tracking works (remaining_budget decrements after execute).
  </done>
</task>

<task type="auto">
  <name>Task 2: Update query package exports</name>
  <files>src/query/__init__.py</files>
  <action>
Update `src/query/__init__.py` to import and re-export from _scheduler.py:
- SourceScheduler
- PerSecondLimiter
- WindowLimiter
- create_google_scheduler
- create_newsdata_scheduler
- create_gnews_scheduler

Add all 6 symbols to __all__. Keep existing exports from _models.py and _generator.py.
  </action>
  <verify>
Run: `python -c "from src.query import SourceScheduler, PerSecondLimiter, WindowLimiter, create_google_scheduler, create_newsdata_scheduler, create_gnews_scheduler; print('All scheduler exports OK')"`
  </verify>
  <done>
All scheduler symbols importable from src.query package. __all__ updated with all public symbols.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from src.query import SourceScheduler, create_google_scheduler, create_newsdata_scheduler, create_gnews_scheduler"` -- imports succeed
2. Google scheduler has unlimited budget (remaining_budget is None), concurrency=5
3. NewsData scheduler has 200 daily budget, 30/15min window limiter
4. GNews scheduler has 100 daily budget, 1/s rate limit
5. SourceScheduler.execute() never raises -- returns QueryResult with success=False on error
6. Budget-exhausted scheduler returns QueryResult with error="budget_exhausted" without making HTTP request
7. Language filtering returns QueryResult with error="unsupported_language" for unsupported languages
</verification>

<success_criteria>
- PerSecondLimiter enforces per-request delay with jitter
- WindowLimiter enforces rolling window limits
- SourceScheduler wraps any NewsSource with rate limiting and budget tracking
- Factory functions create correctly-configured schedulers for all 3 sources
- execute() NEVER raises exceptions (returns error QueryResult instead)
- src/query package exports all scheduler symbols
</success_criteria>

<output>
After completion, create `.planning/phases/06-query-engine-and-scheduling/06-02-SUMMARY.md`
</output>
